#### Backtracking, or backpropagation, is a key process in training neural networks. It involves taking the error rate from forward propagation and feeding this loss backward through the network layers to adjust the weights. This process often involves using the chain rule and other calculus-derived methods. 

<br>

## **Steps of backtracking**

<br>

#### **Forward Propagation:** Input data passes through the network to produce an output.
#### **Loss Calculation:** The difference between the predicted output and the actual target (loss) is calculated.
#### **Backward Propagation:** The loss is propagated back through the network, updating the weights to minimize the error.

<br>

Resources 
https://journalofbigdata.springeropen.com/articles/10.1186/s40537-017-0101-8 
https://www.javatpoint.com/pytorch-backpropagation-process-in-deep-neural-network 
https://365datascience.com/trending/backpropagation/ 
