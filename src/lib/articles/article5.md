#### Backtracking, or backpropagation, is a key process in training neural networks. It involves taking the error rate from forward propagation and feeding this loss backward through the network layers to adjust the weights. This process often involves using the chain rule and other calculus-derived methods. 

<!-- ![Image0](/static/articleimages/loss_functions/image0) -->

<br>

### Steps of backtracking
Forward Propagation: Input data passes through the network to produce an output.
Loss Calculation: The difference between the predicted output and the actual target (loss) is calculated.
Backward Propagation: The loss is propagated back through the network, updating the weights to minimize the error.

<br>

### *References*
Backpropagation Process in Deep Neural Network - javatpoint. (n.d.). Javatpoint. Retrieved August 6, 2024, from https://www.javatpoint.com/pytorch-backpropagation-process-in-deep-neural-network
Fang, X. (2017, November 13). Understanding deep learning via backtracking and deconvolution - Journal of Big Data. Journal of Big Data. Retrieved August 6, 2024, from https://journalofbigdata.springeropen.com/articles/10.1186/s40537-017-0101-8
